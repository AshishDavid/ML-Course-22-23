{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshishDavid/ML-Course-22-23/blob/Spring-2023/HW_2/CNN_for_texts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13pL--6rycN3"
      },
      "source": [
        "## Homework02: Three headed network in PyTorch\n",
        "\n",
        "This notebook accompanies the [week02](https://github.com/girafe-ai/natural-language-processing/tree/master/week02_cnn_for_texts) practice session. Refer to that notebook for more comments.\n",
        "\n",
        "All the preprocessing is the same as in the classwork. *Including the data leakage in the train test split (it's still for bonus points).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P8zS7m-gycN5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "import tqdm\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTdpKSwXnvzl"
      },
      "source": [
        "If you have already downloaded the data on the Seminar, simply run through the next cells. Otherwise uncomment the next cell (and comment the another one ;)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z6J1WIXrnvzl",
        "outputId": "253503a5-5b9a-42ca-f339-01e01c32bae4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100    17    0    17    0     0     48      0 --:--:-- --:--:-- --:--:--    48\n",
            "100   342  100   342    0     0    435      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  119M  100  119M    0     0  22.8M      0  0:00:05  0:00:05 --:--:-- 31.4M\n",
            "Train_rev1.csv\n",
            "--2023-06-01 08:27:13--  https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22f_msai/homeworks/assignment02_three_headed_network/network.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1469 (1.4K) [text/plain]\n",
            "Saving to: ‘network.py’\n",
            "\n",
            "network.py          100%[===================>]   1.43K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-01 08:27:13 (32.9 MB/s) - ‘network.py’ saved [1469/1469]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# # uncomment and run this cell, if you don't have data locally yet.\n",
        "\n",
        "# !curl -L \"https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1\" -o Train_rev1.csv.tar.gz\n",
        "# !tar -xvzf ./Train_rev1.csv.tar.gz\n",
        "\n",
        "# data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n",
        "\n",
        "# !wget https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22f_msai/homeworks/assignment02_three_headed_network/network.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vwN72gd4ycOA"
      },
      "outputs": [],
      "source": [
        "# run this cell if you have downloaded the dataset on the seminar\n",
        "data = pd.read_csv(\"Train_rev1.csv\", index_col=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UuuKIKfrycOH"
      },
      "outputs": [],
      "source": [
        "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
        "text_columns = [\"Title\", \"FullDescription\"]\n",
        "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
        "target_column = \"Log1pSalary\"\n",
        "\n",
        "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
        "\n",
        "data.sample(3)\n",
        "\n",
        "\n",
        "data_for_autotest = data[-5000:]\n",
        "data = data[:-5000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RUWkpd7PycOQ",
        "outputId": "ab2dca58-32ef-4f9c-e6ae-77cadd3e1162",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized:\n",
            "2         mathematical modeller / simulation analyst / o...\n",
            "100002    a successful and high achieving specialist sch...\n",
            "200002    web designer html , css , javascript , photosh...\n",
            "Name: FullDescription, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "239768it [00:31, 7522.91it/s] \n"
          ]
        }
      ],
      "source": [
        "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
        "# see task above\n",
        "def normalize(text):\n",
        "    text = str(text).lower()\n",
        "    return ' '.join(tokenizer.tokenize(text))\n",
        "    \n",
        "data[text_columns] = data[text_columns].applymap(normalize)\n",
        "\n",
        "print(\"Tokenized:\")\n",
        "print(data[\"FullDescription\"][2::100000])\n",
        "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
        "assert data[\"Title\"][54321] == 'international digital account manager ( german )'\n",
        "\n",
        "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
        "# build a dictionary { token -> it's count }\n",
        "from collections import Counter\n",
        "from tqdm import tqdm as tqdm\n",
        "\n",
        "token_counts = Counter()# <YOUR CODE HERE>\n",
        "for _, row in tqdm(data[text_columns].iterrows()):\n",
        "    for string in row:\n",
        "        token_counts.update(string.split())\n",
        "\n",
        "# hint: you may or may not want to use collections.Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZP_YhgOQnvzo",
        "outputId": "f1362530-89d5-4c1c-ea50-84fc437245c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2598827"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "token_counts.most_common(1)[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiOWbc15ycOb",
        "outputId": "e9ae27c6-faa9-4f3c-e0cf-c282be6c14ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique tokens : 201127\n",
            "('and', 2598827)\n",
            "('.', 2471477)\n",
            "(',', 2266256)\n",
            "('the', 2036428)\n",
            "('to', 1977039)\n",
            "...\n",
            "('dbms_stats', 1)\n",
            "('dbms_output', 1)\n",
            "('dbms_job', 1)\n",
            "Correct!\n",
            "Vocabulary size: 33795\n",
            "Correct!\n",
            "Correct!\n"
          ]
        }
      ],
      "source": [
        "print(\"Total unique tokens :\", len(token_counts))\n",
        "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
        "print('...')\n",
        "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
        "\n",
        "assert token_counts.most_common(1)[0][1] in  range(2500000, 2700000)\n",
        "assert len(token_counts) in range(200000, 210000)\n",
        "print('Correct!')\n",
        "\n",
        "min_count = 10\n",
        "\n",
        "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
        "tokens = [token for token, count in token_counts.items() if count >= min_count]# <YOUR CODE HERE>\n",
        "# Add a special tokens for unknown and empty words\n",
        "UNK, PAD = \"UNK\", \"PAD\"\n",
        "tokens = [UNK, PAD] + sorted(tokens)\n",
        "print(\"Vocabulary size:\", len(tokens))\n",
        "\n",
        "assert type(tokens) == list\n",
        "assert len(tokens) in range(32000, 35000)\n",
        "assert 'me' in tokens\n",
        "assert UNK in tokens\n",
        "print(\"Correct!\")\n",
        "\n",
        "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
        "assert isinstance(token_to_id, dict)\n",
        "assert len(token_to_id) == len(tokens)\n",
        "for tok in tokens:\n",
        "    assert tokens[token_to_id[tok]] == tok\n",
        "\n",
        "print(\"Correct!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "JEsLeBjVycOw"
      },
      "outputs": [],
      "source": [
        "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
        "\n",
        "def as_matrix(sequences, max_len=None):\n",
        "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
        "    if isinstance(sequences[0], str):\n",
        "        sequences = list(map(str.split, sequences))\n",
        "        \n",
        "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
        "    \n",
        "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
        "    for i,seq in enumerate(sequences):\n",
        "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
        "        matrix[i, :len(row_ix)] = row_ix\n",
        "    \n",
        "    return matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiBlPkdKycOy",
        "outputId": "45ab8532-cdc9-4079-83e7-64d749623e53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lines:\n",
            "engineering systems analyst\n",
            "hr assistant\n",
            "senior ec & i engineer\n",
            "\n",
            "Matrix:\n",
            "[[10705 29830  2143     1     1]\n",
            " [14875  2817     1     1     1]\n",
            " [27345 10107    15 15069 10702]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Lines:\")\n",
        "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
        "print(\"Matrix:\")\n",
        "print(as_matrix(data[\"Title\"][::100000]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "DpOlBp7ZycO6",
        "outputId": "cc9875b2-37c8-4965-c2bf-16c28654547b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DictVectorizer(dtype=<class 'numpy.float32'>, sparse=False)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DictVectorizer</label><div class=\"sk-toggleable__content\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "# we only consider top-1k most frequent companies to minimize memory usage\n",
        "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
        "recognized_companies = set(top_companies)\n",
        "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
        "\n",
        "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
        "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk4jmtAYycO8"
      },
      "source": [
        "### The deep learning part\n",
        "\n",
        "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
        "\n",
        "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
        "\n",
        "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes.\n",
        "\n",
        "\n",
        "#### Here comes the simple one-headed network from the seminar. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TngLcWA0ycO_",
        "outputId": "1d64dbbc-69af-4d40-dd57-bde126280bd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size =  191814\n",
            "Validation size =  47954\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
        "data_train.index = range(len(data_train))\n",
        "data_val.index = range(len(data_val))\n",
        "\n",
        "print(\"Train size = \", len(data_train))\n",
        "print(\"Validation size = \", len(data_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2PXuKgOSycPB"
      },
      "outputs": [],
      "source": [
        "def make_batch(data, max_len=None, word_dropout=0):\n",
        "    \"\"\"\n",
        "    Creates a keras-friendly dict from the batch data.\n",
        "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
        "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
        "    \"\"\"\n",
        "    batch = {}\n",
        "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
        "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
        "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
        "    \n",
        "    if word_dropout != 0:\n",
        "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
        "    \n",
        "    if target_column in data.columns:\n",
        "        batch[target_column] = data[target_column].values\n",
        "    \n",
        "    return batch\n",
        "\n",
        "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
        "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
        "    dropout_mask &= matrix != pad_ix\n",
        "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6LpEQf0ycPD"
      },
      "outputs": [],
      "source": [
        "a = make_batch(data_train[:3], max_len=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-6Vm98tnvzr"
      },
      "source": [
        "But to start with let's build the simple model using only the part of the data. Let's create the baseline solution using only the description part (so it should definetely fit into the Sequential model)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ePGLx2jInvzs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zWkcmdgnvzs"
      },
      "outputs": [],
      "source": [
        "# You will need these to make it simple\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "class Reorder(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.permute((0, 2, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Lj6Ng2Ynvzs"
      },
      "source": [
        "To generate minibatches we will use simple pyton generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UsyM88mmnvzs"
      },
      "outputs": [],
      "source": [
        "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
        "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
        "    while True:\n",
        "        indices = np.arange(len(data))\n",
        "        if shuffle:\n",
        "            indices = np.random.permutation(indices)\n",
        "\n",
        "        for start in range(0, len(indices), batch_size):\n",
        "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
        "            target = batch.pop(target_column)\n",
        "            yield batch, target\n",
        "        \n",
        "        if not cycle: break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HsmO6pZOnvzt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "1035c401-43c2-4702-d8cc-8bf33523193b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-659b79569bd1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'iterate_minibatches' is not defined"
          ]
        }
      ],
      "source": [
        "iterator = iterate_minibatches(data_train, 3)\n",
        "batch, target = next(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "A3uy2Q-Knvzt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "34614e32-4ebe-49e9-c5fe-2d24ba23b6ff"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-de75ad046c7e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Here is some startup code:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mn_cat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mhid_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msimple_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'categorical_vectorizer' is not defined"
          ]
        }
      ],
      "source": [
        "# Here is some startup code:\n",
        "n_tokens=len(tokens)\n",
        "n_cat_features=len(categorical_vectorizer.vocabulary_)\n",
        "hid_size=64\n",
        "simple_model = nn.Sequential()\n",
        "\n",
        "simple_model.add_module('emb', nn.Embedding(num_embeddings=n_tokens, embedding_dim=hid_size))\n",
        "simple_model.add_module('reorder', Reorder())\n",
        "simple_model.add_module('conv1', nn.Conv1d(\n",
        "    in_channels=hid_size,\n",
        "    out_channels=hid_size,\n",
        "    kernel_size=2)\n",
        "                       )\n",
        "simple_model.add_module('relu1', nn.ReLU())\n",
        "simple_model.add_module('adapt_avg_pool', nn.AdaptiveAvgPool1d(output_size=1))\n",
        "simple_model.add_module('flatten1', Flatten())\n",
        "simple_model.add_module('linear1', nn.Linear(in_features=hid_size, out_features=1))\n",
        "# <YOUR CODE HERE>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgiqEoIDnvzt",
        "outputId": "fdf1650f-912b-4df4-ea54-04b05680a9a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Title': array([[19217, 26688,  7252,     1],\n",
              "        [29096, 18670,  8895, 33628],\n",
              "        [10868,  7468,     1,     1]], dtype=int32),\n",
              " 'FullDescription': array([[29654, 20742, 14109, ...,     1,     1,     1],\n",
              "        [25927, 16658, 21721, ...,     1,     1,     1],\n",
              "        [10868,  7468,  3551, ..., 10572,  4938,   167]], dtype=int32),\n",
              " 'Categorical': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 1., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5N-q5wVnvzt"
      },
      "source": [
        "__Remember!__ We are working with regression problem and predicting only one number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RLdWPY0nvzu",
        "outputId": "7e45512e-33fc-4494-9ac8-d78e251dad08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2805],\n",
              "        [0.2820],\n",
              "        [0.2546]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "# Try this to check your model. `torch.long` tensors are required for nn.Embedding layers.\n",
        "simple_model(torch.tensor(batch['FullDescription'], dtype=torch.long))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSdwwOA7nvzu",
        "outputId": "11d9b55a-f7a3-4f77-fe99-f3799f1c64fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 428)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "batch['FullDescription'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lznGHvJBnvzu"
      },
      "source": [
        "And now simple training pipeline (it's commented because we've already done that in class. No need to do it again)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fjrwoIynvzv"
      },
      "outputs": [],
      "source": [
        "# from IPython.display import clear_output\n",
        "# from random import sample\n",
        "\n",
        "# epochs = 1\n",
        "\n",
        "# model = simple_model\n",
        "# opt = torch.optim.Adam(model.parameters())\n",
        "# loss_func = nn.MSELoss()\n",
        "\n",
        "# history = []\n",
        "# for epoch_num in range(epochs):\n",
        "#     for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
        "#         # Preprocessing the batch data and target\n",
        "#         batch = torch.tensor(batch['FullDescription'], dtype=torch.long)\n",
        "\n",
        "#         target = torch.tensor(target)\n",
        "\n",
        "\n",
        "#         predictions = model(batch)\n",
        "#         predictions = predictions.view(predictions.size(0))\n",
        "\n",
        "#         loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
        "\n",
        "#         # train with backprop\n",
        "#         loss.backward()\n",
        "#         opt.step()\n",
        "#         opt.zero_grad()\n",
        "#         # <YOUR CODE HERE>\n",
        "\n",
        "#         history.append(loss.data.numpy())\n",
        "#         if (idx+1)%10==0:\n",
        "#             clear_output(True)\n",
        "#             plt.plot(history,label='loss')\n",
        "#             plt.legend()\n",
        "#             plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlDFUnR9nvzv"
      },
      "source": [
        "### Actual homework starts here\n",
        "__Your ultimate task is to code the three headed network described on the picture below.__ \n",
        "To make it closer to the real world, please store the network code in file `network.py` in this directory. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eI5h9UMycPF"
      },
      "source": [
        "#### Architecture\n",
        "\n",
        "Our main model consists of three branches:\n",
        "* Title encoder\n",
        "* Description encoder\n",
        "* Categorical features encoder\n",
        "\n",
        "We will then feed all 3 branches into one common network that predicts salary.\n",
        "\n",
        "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>\n",
        "\n",
        "This clearly doesn't fit into PyTorch __Sequential__ interface. To build such a network, one will have to use [__PyTorch nn.Module API__](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "8mIwBKX1nvzw"
      },
      "outputs": [],
      "source": [
        "import network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "8AcAyRcRnvzw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa811f4a-12a1-4866-b251-1462b12ab291"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'network' from '/content/network.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# Re-run this cell if you updated the file with network source code\n",
        "import imp\n",
        "imp.reload(network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ZFVW8mLBnvzw"
      },
      "outputs": [],
      "source": [
        "model = network.ThreeInputsNet(\n",
        "    num_tokens=len(tokens),\n",
        "    num_cat_features=len(categorical_vectorizer.vocabulary_),\n",
        "    concat_features=192,\n",
        "    hidden_size=64\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "nfxkrTm5nvzx"
      },
      "outputs": [],
      "source": [
        "testing_batch, _ = next(iterate_minibatches(data_train, 3))\n",
        "testing_batch = [\n",
        "    torch.tensor(testing_batch['Title'], dtype=torch.long),\n",
        "    torch.tensor(testing_batch['FullDescription'], dtype=torch.long),\n",
        "    torch.tensor(testing_batch['Categorical'])\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "7-1oYIjfnvzx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c75076b1-4ec7-489b-e13a-1798df922575"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seems fine!\n"
          ]
        }
      ],
      "source": [
        "assert model(testing_batch).shape == torch.Size([3, 1])\n",
        "assert model(testing_batch).dtype == torch.float32\n",
        "print('Seems fine!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dQCYqmmnvzx"
      },
      "source": [
        "Now train the network for a while (100 batches would be fine)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "WksGxmvenvzx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "f96ee1d2-05e9-46f9-85af-81aa9c001c56"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "model = model.to(device)\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "history = []\n",
        "for epoch_num in range(epochs):\n",
        "    for idx, (input_batch, target) in enumerate(iterate_minibatches(data_train)):\n",
        "        title_ix = torch.tensor(input_batch['Title'], dtype=torch.long).to(device)\n",
        "        desc_ix = torch.tensor(input_batch['FullDescription'], dtype=torch.long).to(device)\n",
        "        cat_features = torch.tensor(input_batch['Categorical'], dtype=torch.long).to(device)\n",
        "        target = torch.tensor(target, dtype=torch.float32).to(device)\n",
        "\n",
        "        predictions = model((title_ix, desc_ix, cat_features))\n",
        "        predictions = predictions.view(predictions.size(0))\n",
        "\n",
        "        loss = loss_func(predictions, target)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        history.append(loss.item())\n",
        "        if (idx + 1) % 10 == 0:\n",
        "            clear_output(True)\n",
        "            plt.plot(history, label='loss')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n",
        "        if idx + 1 >= 100:  # Stop after 100 batches\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyk8sZQbnvzx"
      },
      "source": [
        "Now, to evaluate the model it can be switched to `eval` state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "SKkfQ6cdnv0Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c8eaace-58b7-4215-b3c2-cabb73992485"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ThreeInputsNet(\n",
              "  (title_embedding): Embedding(33795, 64)\n",
              "  (title_conv_layer): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "  (full_embedding): Embedding(33795, 64)\n",
              "  (full_conv_layer): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "  (cat_embedding): Embedding(3746, 64)\n",
              "  (cat_output_layer): Linear(in_features=239744, out_features=64, bias=True)\n",
              "  (intermediate_layer): Linear(in_features=192, out_features=128, bias=True)\n",
              "  (additional_layer1): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (additional_layer2): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "NGRH1LICnv0R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "160e497c-1b48-4e7f-8ad3-edeee9b7ea48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20it [00:00, 23.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission results:\n",
            "Mean square error: 0.25190\n",
            "Mean absolute error: 0.40757\n",
            "Submission file generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def generate_submission(model, data, batch_size=256, name=\"\", three_inputs_mode=True, **kw):\n",
        "    squared_error = abs_error = num_samples = 0.0\n",
        "    output_list = []\n",
        "    model = model.to(device)  # Move the model to the correct device\n",
        "    for batch_x, batch_y in tqdm(iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw)):\n",
        "        if three_inputs_mode:\n",
        "            batch = [\n",
        "                torch.tensor(batch_x['Title'], dtype=torch.long).to(device),  # Move tensors to the correct device\n",
        "                torch.tensor(batch_x['FullDescription'], dtype=torch.long).to(device),\n",
        "                torch.tensor(batch_x['Categorical']).to(device)\n",
        "            ]\n",
        "        else:\n",
        "            batch = torch.tensor(batch_x['FullDescription'], dtype=torch.long).to(device)\n",
        "\n",
        "        batch_pred = model(batch)[:, 0].detach().cpu().numpy()  # Move the predictions back to the CPU\n",
        "        \n",
        "        output_list.append((list(batch_pred), list(batch_y)))\n",
        "        \n",
        "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
        "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
        "        num_samples += len(batch_y)\n",
        "    print(\"%s results:\" % (name or \"\"))\n",
        "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
        "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
        "    \n",
        "\n",
        "    batch_pred = [c for x in output_list for c in x[0]]\n",
        "    batch_y = [c for x in output_list for c in x[1]]\n",
        "    output_df = pd.DataFrame(list(zip(batch_pred, batch_y)), columns=['batch_pred', 'batch_y'])\n",
        "    output_df.to_csv('submission.csv', index=False)\n",
        "\n",
        "generate_submission(model, data_for_autotest, name='Submission')\n",
        "print('Submission file generated')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "EBlVia_tnv0S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e90bcad1-2305-4a27-8b90-3ea6cad58c16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20it [00:00, 23.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission results:\n",
            "Mean square error: 0.25190\n",
            "Mean absolute error: 0.40757\n",
            "Submission file generated\n"
          ]
        }
      ],
      "source": [
        "generate_submission(model, data_for_autotest, name='Submission')\n",
        "print('Submission file generated')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otLC6zHznv0T"
      },
      "source": [
        "__Both the notebook and the `.py` file are required to submit this homework.__"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Py3 research env",
      "language": "python",
      "name": "py3_research"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}