{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshishDavid/ML-Course-22-23/blob/Spring-2023/HW_2/CNN_for_texts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13pL--6rycN3"
      },
      "source": [
        "## Homework02: Three headed network in PyTorch\n",
        "\n",
        "This notebook accompanies the [week02](https://github.com/girafe-ai/natural-language-processing/tree/master/week02_cnn_for_texts) practice session. Refer to that notebook for more comments.\n",
        "\n",
        "All the preprocessing is the same as in the classwork. *Including the data leakage in the train test split (it's still for bonus points).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P8zS7m-gycN5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "import tqdm\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTdpKSwXnvzl"
      },
      "source": [
        "If you have already downloaded the data on the Seminar, simply run through the next cells. Otherwise uncomment the next cell (and comment the another one ;)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z6J1WIXrnvzl",
        "outputId": "253503a5-5b9a-42ca-f339-01e01c32bae4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100    17    0    17    0     0     48      0 --:--:-- --:--:-- --:--:--    48\n",
            "100   342  100   342    0     0    435      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  119M  100  119M    0     0  22.8M      0  0:00:05  0:00:05 --:--:-- 31.4M\n",
            "Train_rev1.csv\n",
            "--2023-06-01 08:27:13--  https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22f_msai/homeworks/assignment02_three_headed_network/network.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1469 (1.4K) [text/plain]\n",
            "Saving to: ‘network.py’\n",
            "\n",
            "network.py          100%[===================>]   1.43K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-01 08:27:13 (32.9 MB/s) - ‘network.py’ saved [1469/1469]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# # uncomment and run this cell, if you don't have data locally yet.\n",
        "\n",
        "# !curl -L \"https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1\" -o Train_rev1.csv.tar.gz\n",
        "# !tar -xvzf ./Train_rev1.csv.tar.gz\n",
        "\n",
        "# data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n",
        "\n",
        "# !wget https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22f_msai/homeworks/assignment02_three_headed_network/network.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vwN72gd4ycOA"
      },
      "outputs": [],
      "source": [
        "# run this cell if you have downloaded the dataset on the seminar\n",
        "data = pd.read_csv(\"Train_rev1.csv\", index_col=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UuuKIKfrycOH"
      },
      "outputs": [],
      "source": [
        "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
        "text_columns = [\"Title\", \"FullDescription\"]\n",
        "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
        "target_column = \"Log1pSalary\"\n",
        "\n",
        "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
        "\n",
        "data.sample(3)\n",
        "\n",
        "\n",
        "data_for_autotest = data[-5000:]\n",
        "data = data[:-5000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RUWkpd7PycOQ",
        "outputId": "ab2dca58-32ef-4f9c-e6ae-77cadd3e1162",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized:\n",
            "2         mathematical modeller / simulation analyst / o...\n",
            "100002    a successful and high achieving specialist sch...\n",
            "200002    web designer html , css , javascript , photosh...\n",
            "Name: FullDescription, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "239768it [00:31, 7522.91it/s] \n"
          ]
        }
      ],
      "source": [
        "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
        "# see task above\n",
        "def normalize(text):\n",
        "    text = str(text).lower()\n",
        "    return ' '.join(tokenizer.tokenize(text))\n",
        "    \n",
        "data[text_columns] = data[text_columns].applymap(normalize)\n",
        "\n",
        "print(\"Tokenized:\")\n",
        "print(data[\"FullDescription\"][2::100000])\n",
        "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
        "assert data[\"Title\"][54321] == 'international digital account manager ( german )'\n",
        "\n",
        "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
        "# build a dictionary { token -> it's count }\n",
        "from collections import Counter\n",
        "from tqdm import tqdm as tqdm\n",
        "\n",
        "token_counts = Counter()# <YOUR CODE HERE>\n",
        "for _, row in tqdm(data[text_columns].iterrows()):\n",
        "    for string in row:\n",
        "        token_counts.update(string.split())\n",
        "\n",
        "# hint: you may or may not want to use collections.Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZP_YhgOQnvzo",
        "outputId": "f1362530-89d5-4c1c-ea50-84fc437245c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2598827"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "token_counts.most_common(1)[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiOWbc15ycOb",
        "outputId": "e9ae27c6-faa9-4f3c-e0cf-c282be6c14ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique tokens : 201127\n",
            "('and', 2598827)\n",
            "('.', 2471477)\n",
            "(',', 2266256)\n",
            "('the', 2036428)\n",
            "('to', 1977039)\n",
            "...\n",
            "('dbms_stats', 1)\n",
            "('dbms_output', 1)\n",
            "('dbms_job', 1)\n",
            "Correct!\n",
            "Vocabulary size: 33795\n",
            "Correct!\n",
            "Correct!\n"
          ]
        }
      ],
      "source": [
        "print(\"Total unique tokens :\", len(token_counts))\n",
        "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
        "print('...')\n",
        "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
        "\n",
        "assert token_counts.most_common(1)[0][1] in  range(2500000, 2700000)\n",
        "assert len(token_counts) in range(200000, 210000)\n",
        "print('Correct!')\n",
        "\n",
        "min_count = 10\n",
        "\n",
        "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
        "tokens = [token for token, count in token_counts.items() if count >= min_count]# <YOUR CODE HERE>\n",
        "# Add a special tokens for unknown and empty words\n",
        "UNK, PAD = \"UNK\", \"PAD\"\n",
        "tokens = [UNK, PAD] + sorted(tokens)\n",
        "print(\"Vocabulary size:\", len(tokens))\n",
        "\n",
        "assert type(tokens) == list\n",
        "assert len(tokens) in range(32000, 35000)\n",
        "assert 'me' in tokens\n",
        "assert UNK in tokens\n",
        "print(\"Correct!\")\n",
        "\n",
        "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
        "assert isinstance(token_to_id, dict)\n",
        "assert len(token_to_id) == len(tokens)\n",
        "for tok in tokens:\n",
        "    assert tokens[token_to_id[tok]] == tok\n",
        "\n",
        "print(\"Correct!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "JEsLeBjVycOw"
      },
      "outputs": [],
      "source": [
        "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
        "\n",
        "def as_matrix(sequences, max_len=None):\n",
        "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
        "    if isinstance(sequences[0], str):\n",
        "        sequences = list(map(str.split, sequences))\n",
        "        \n",
        "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
        "    \n",
        "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
        "    for i,seq in enumerate(sequences):\n",
        "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
        "        matrix[i, :len(row_ix)] = row_ix\n",
        "    \n",
        "    return matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiBlPkdKycOy",
        "outputId": "45ab8532-cdc9-4079-83e7-64d749623e53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lines:\n",
            "engineering systems analyst\n",
            "hr assistant\n",
            "senior ec & i engineer\n",
            "\n",
            "Matrix:\n",
            "[[10705 29830  2143     1     1]\n",
            " [14875  2817     1     1     1]\n",
            " [27345 10107    15 15069 10702]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Lines:\")\n",
        "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
        "print(\"Matrix:\")\n",
        "print(as_matrix(data[\"Title\"][::100000]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "DpOlBp7ZycO6",
        "outputId": "cc9875b2-37c8-4965-c2bf-16c28654547b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DictVectorizer(dtype=<class 'numpy.float32'>, sparse=False)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DictVectorizer</label><div class=\"sk-toggleable__content\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "# we only consider top-1k most frequent companies to minimize memory usage\n",
        "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
        "recognized_companies = set(top_companies)\n",
        "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
        "\n",
        "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
        "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk4jmtAYycO8"
      },
      "source": [
        "### The deep learning part\n",
        "\n",
        "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
        "\n",
        "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
        "\n",
        "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes.\n",
        "\n",
        "\n",
        "#### Here comes the simple one-headed network from the seminar. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TngLcWA0ycO_",
        "outputId": "1d64dbbc-69af-4d40-dd57-bde126280bd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size =  191814\n",
            "Validation size =  47954\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
        "data_train.index = range(len(data_train))\n",
        "data_val.index = range(len(data_val))\n",
        "\n",
        "print(\"Train size = \", len(data_train))\n",
        "print(\"Validation size = \", len(data_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2PXuKgOSycPB"
      },
      "outputs": [],
      "source": [
        "def make_batch(data, max_len=None, word_dropout=0):\n",
        "    \"\"\"\n",
        "    Creates a keras-friendly dict from the batch data.\n",
        "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
        "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
        "    \"\"\"\n",
        "    batch = {}\n",
        "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
        "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
        "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
        "    \n",
        "    if word_dropout != 0:\n",
        "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
        "    \n",
        "    if target_column in data.columns:\n",
        "        batch[target_column] = data[target_column].values\n",
        "    \n",
        "    return batch\n",
        "\n",
        "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
        "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
        "    dropout_mask &= matrix != pad_ix\n",
        "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6LpEQf0ycPD"
      },
      "outputs": [],
      "source": [
        "a = make_batch(data_train[:3], max_len=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-6Vm98tnvzr"
      },
      "source": [
        "But to start with let's build the simple model using only the part of the data. Let's create the baseline solution using only the description part (so it should definetely fit into the Sequential model)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ePGLx2jInvzs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zWkcmdgnvzs"
      },
      "outputs": [],
      "source": [
        "# You will need these to make it simple\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "class Reorder(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.permute((0, 2, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Lj6Ng2Ynvzs"
      },
      "source": [
        "To generate minibatches we will use simple pyton generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UsyM88mmnvzs"
      },
      "outputs": [],
      "source": [
        "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
        "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
        "    while True:\n",
        "        indices = np.arange(len(data))\n",
        "        if shuffle:\n",
        "            indices = np.random.permutation(indices)\n",
        "\n",
        "        for start in range(0, len(indices), batch_size):\n",
        "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
        "            target = batch.pop(target_column)\n",
        "            yield batch, target\n",
        "        \n",
        "        if not cycle: break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HsmO6pZOnvzt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "1035c401-43c2-4702-d8cc-8bf33523193b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-659b79569bd1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'iterate_minibatches' is not defined"
          ]
        }
      ],
      "source": [
        "iterator = iterate_minibatches(data_train, 3)\n",
        "batch, target = next(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "A3uy2Q-Knvzt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "34614e32-4ebe-49e9-c5fe-2d24ba23b6ff"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-de75ad046c7e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Here is some startup code:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mn_cat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mhid_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msimple_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'categorical_vectorizer' is not defined"
          ]
        }
      ],
      "source": [
        "# Here is some startup code:\n",
        "n_tokens=len(tokens)\n",
        "n_cat_features=len(categorical_vectorizer.vocabulary_)\n",
        "hid_size=64\n",
        "simple_model = nn.Sequential()\n",
        "\n",
        "simple_model.add_module('emb', nn.Embedding(num_embeddings=n_tokens, embedding_dim=hid_size))\n",
        "simple_model.add_module('reorder', Reorder())\n",
        "simple_model.add_module('conv1', nn.Conv1d(\n",
        "    in_channels=hid_size,\n",
        "    out_channels=hid_size,\n",
        "    kernel_size=2)\n",
        "                       )\n",
        "simple_model.add_module('relu1', nn.ReLU())\n",
        "simple_model.add_module('adapt_avg_pool', nn.AdaptiveAvgPool1d(output_size=1))\n",
        "simple_model.add_module('flatten1', Flatten())\n",
        "simple_model.add_module('linear1', nn.Linear(in_features=hid_size, out_features=1))\n",
        "# <YOUR CODE HERE>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgiqEoIDnvzt",
        "outputId": "fdf1650f-912b-4df4-ea54-04b05680a9a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Title': array([[19217, 26688,  7252,     1],\n",
              "        [29096, 18670,  8895, 33628],\n",
              "        [10868,  7468,     1,     1]], dtype=int32),\n",
              " 'FullDescription': array([[29654, 20742, 14109, ...,     1,     1,     1],\n",
              "        [25927, 16658, 21721, ...,     1,     1,     1],\n",
              "        [10868,  7468,  3551, ..., 10572,  4938,   167]], dtype=int32),\n",
              " 'Categorical': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 1., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5N-q5wVnvzt"
      },
      "source": [
        "__Remember!__ We are working with regression problem and predicting only one number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RLdWPY0nvzu",
        "outputId": "7e45512e-33fc-4494-9ac8-d78e251dad08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2805],\n",
              "        [0.2820],\n",
              "        [0.2546]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "# Try this to check your model. `torch.long` tensors are required for nn.Embedding layers.\n",
        "simple_model(torch.tensor(batch['FullDescription'], dtype=torch.long))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSdwwOA7nvzu",
        "outputId": "11d9b55a-f7a3-4f77-fe99-f3799f1c64fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 428)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "batch['FullDescription'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lznGHvJBnvzu"
      },
      "source": [
        "And now simple training pipeline (it's commented because we've already done that in class. No need to do it again)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fjrwoIynvzv"
      },
      "outputs": [],
      "source": [
        "# from IPython.display import clear_output\n",
        "# from random import sample\n",
        "\n",
        "# epochs = 1\n",
        "\n",
        "# model = simple_model\n",
        "# opt = torch.optim.Adam(model.parameters())\n",
        "# loss_func = nn.MSELoss()\n",
        "\n",
        "# history = []\n",
        "# for epoch_num in range(epochs):\n",
        "#     for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
        "#         # Preprocessing the batch data and target\n",
        "#         batch = torch.tensor(batch['FullDescription'], dtype=torch.long)\n",
        "\n",
        "#         target = torch.tensor(target)\n",
        "\n",
        "\n",
        "#         predictions = model(batch)\n",
        "#         predictions = predictions.view(predictions.size(0))\n",
        "\n",
        "#         loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
        "\n",
        "#         # train with backprop\n",
        "#         loss.backward()\n",
        "#         opt.step()\n",
        "#         opt.zero_grad()\n",
        "#         # <YOUR CODE HERE>\n",
        "\n",
        "#         history.append(loss.data.numpy())\n",
        "#         if (idx+1)%10==0:\n",
        "#             clear_output(True)\n",
        "#             plt.plot(history,label='loss')\n",
        "#             plt.legend()\n",
        "#             plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlDFUnR9nvzv"
      },
      "source": [
        "### Actual homework starts here\n",
        "__Your ultimate task is to code the three headed network described on the picture below.__ \n",
        "To make it closer to the real world, please store the network code in file `network.py` in this directory. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eI5h9UMycPF"
      },
      "source": [
        "#### Architecture\n",
        "\n",
        "Our main model consists of three branches:\n",
        "* Title encoder\n",
        "* Description encoder\n",
        "* Categorical features encoder\n",
        "\n",
        "We will then feed all 3 branches into one common network that predicts salary.\n",
        "\n",
        "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>\n",
        "\n",
        "This clearly doesn't fit into PyTorch __Sequential__ interface. To build such a network, one will have to use [__PyTorch nn.Module API__](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "8mIwBKX1nvzw"
      },
      "outputs": [],
      "source": [
        "import network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "8AcAyRcRnvzw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba57580e-e24f-4773-f4f4-f0e162801314"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'network' from '/content/network.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "# Re-run this cell if you updated the file with network source code\n",
        "import imp\n",
        "imp.reload(network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "ZFVW8mLBnvzw"
      },
      "outputs": [],
      "source": [
        "model = network.ThreeInputsNet(\n",
        "    n_tokens=len(tokens),\n",
        "    n_cat_features=len(categorical_vectorizer.vocabulary_),\n",
        "    concat_number_of_features=192,\n",
        "    hidden_size=64\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "nfxkrTm5nvzx"
      },
      "outputs": [],
      "source": [
        "testing_batch, _ = next(iterate_minibatches(data_train, 3))\n",
        "testing_batch = [\n",
        "    torch.tensor(testing_batch['Title'], dtype=torch.long),\n",
        "    torch.tensor(testing_batch['FullDescription'], dtype=torch.long),\n",
        "    torch.tensor(testing_batch['Categorical'])\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "7-1oYIjfnvzx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09d049b3-b371-49e7-c9a6-0eb3cb82bcc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seems fine!\n"
          ]
        }
      ],
      "source": [
        "assert model(testing_batch).shape == torch.Size([3, 1])\n",
        "assert model(testing_batch).dtype == torch.float32\n",
        "print('Seems fine!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dQCYqmmnvzx"
      },
      "source": [
        "Now train the network for a while (100 batches would be fine)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "WksGxmvenvzx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "ddffc8d7-eb63-4a04-f163-85c5714f004e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "model = model.to(device)\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "history = []\n",
        "for epoch_num in range(epochs):\n",
        "    for idx, (input_batch, target) in enumerate(iterate_minibatches(data_train)):\n",
        "        title_ix = torch.tensor(input_batch['Title'], dtype=torch.long).to(device)\n",
        "        desc_ix = torch.tensor(input_batch['FullDescription'], dtype=torch.long).to(device)\n",
        "        cat_features = torch.tensor(input_batch['Categorical'], dtype=torch.long).to(device)\n",
        "        target = torch.tensor(target, dtype=torch.float32).to(device)\n",
        "\n",
        "        predictions = model((title_ix, desc_ix, cat_features))\n",
        "        predictions = predictions.view(predictions.size(0))\n",
        "\n",
        "        loss = loss_func(predictions, target)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        history.append(loss.item())\n",
        "        if (idx + 1) % 10 == 0:\n",
        "            clear_output(True)\n",
        "            plt.plot(history, label='loss')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n",
        "        if idx + 1 >= 100:  # Stop after 100 batches\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyk8sZQbnvzx"
      },
      "source": [
        "Now, to evaluate the model it can be switched to `eval` state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "SKkfQ6cdnv0Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a2d7850-7234-4758-a1b6-592ceb19186a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ThreeInputsNet(\n",
              "  (title_embedding): Embedding(33795, 64)\n",
              "  (title_conv_layer): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "  (full_embedding): Embedding(33795, 64)\n",
              "  (full_conv_layer): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "  (cat_embedding): Embedding(3746, 64)\n",
              "  (cat_output_layer): Linear(in_features=239744, out_features=64, bias=True)\n",
              "  (intermediate_layer): Linear(in_features=192, out_features=128, bias=True)\n",
              "  (additional_layer1): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (additional_layer2): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "NGRH1LICnv0R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45c0627c-1844-47b8-f233-a23a2ee0e009"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20it [00:00, 25.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission results:\n",
            "Mean square error: 0.24694\n",
            "Mean absolute error: 0.40338\n",
            "Submission file generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def generate_submission(model, data, batch_size=256, name=\"\", three_inputs_mode=True, **kw):\n",
        "    squared_error = abs_error = num_samples = 0.0\n",
        "    output_list = []\n",
        "    model = model.to(device)  # Move the model to the correct device\n",
        "    for batch_x, batch_y in tqdm(iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw)):\n",
        "        if three_inputs_mode:\n",
        "            batch = [\n",
        "                torch.tensor(batch_x['Title'], dtype=torch.long).to(device),  # Move tensors to the correct device\n",
        "                torch.tensor(batch_x['FullDescription'], dtype=torch.long).to(device),\n",
        "                torch.tensor(batch_x['Categorical']).to(device)\n",
        "            ]\n",
        "        else:\n",
        "            batch = torch.tensor(batch_x['FullDescription'], dtype=torch.long).to(device)\n",
        "\n",
        "        batch_pred = model(batch)[:, 0].detach().cpu().numpy()  # Move the predictions back to the CPU\n",
        "        \n",
        "        output_list.append((list(batch_pred), list(batch_y)))\n",
        "        \n",
        "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
        "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
        "        num_samples += len(batch_y)\n",
        "    print(\"%s results:\" % (name or \"\"))\n",
        "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
        "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
        "    \n",
        "\n",
        "    batch_pred = [c for x in output_list for c in x[0]]\n",
        "    batch_y = [c for x in output_list for c in x[1]]\n",
        "    output_df = pd.DataFrame(list(zip(batch_pred, batch_y)), columns=['batch_pred', 'batch_y'])\n",
        "    output_df.to_csv('submission.csv', index=False)\n",
        "\n",
        "generate_submission(model, data_for_autotest, name='Submission')\n",
        "print('Submission file generated')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "EBlVia_tnv0S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "243a3ce4-ffa9-481d-a64b-6f3e9263ac4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20it [00:00, 25.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission results:\n",
            "Mean square error: 0.24694\n",
            "Mean absolute error: 0.40338\n",
            "Submission file generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "generate_submission(model, data_for_autotest, name='Submission')\n",
        "print('Submission file generated')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otLC6zHznv0T"
      },
      "source": [
        "__Both the notebook and the `.py` file are required to submit this homework.__"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Py3 research env",
      "language": "python",
      "name": "py3_research"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}